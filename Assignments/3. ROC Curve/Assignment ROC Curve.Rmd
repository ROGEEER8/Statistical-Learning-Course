---
title: 'Assignment 3: Comparing discriminant rules. ROC curve and other methods'
author: "Víctor Villegas, Roger Llorenç, Luis Sierra"
date: "2024-03-05"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading the necessary libraries and datasets. 

```{r}

# mmmmm això és el q tinc fet... 
# cap garantia de que estigui bé... 
# he fet l'split de les dades com se m'ha acudit... 
# no sé si s'han d'escalar les dades o no... (no ho fet jo) 
# GLM i GLMNET coincideixen al 100% i no sé si això és una bona senyal...
# Falta l'exercici 6 que va dir a classe què era però no ho recordo...
# S'han de canviar els paths 
# Els comentaris del LASSO de quin són els que afecten més etc ho podem treure...
# I alguna cosa més volia dir però no se m'acut ara

while (dev.cur() != 1) {
  dev.off()
}
# Clears global environment
rm(list=ls())

library(wrapr)
library(glmnet)
library(class)
library(pROC)

path_1 <- ("C:/Users/Roger/Documents/3_UPC/1_Master_math/9_statistical_learning/5_spam_email_database/spambase.data")
df <- read.table(path_1,sep=",")

path_2 <- ("C:/Users/Roger/Documents/3_UPC/1_Master_math/9_statistical_learning/5_spam_email_database/spambase.NAMES")
df.names <- c(read.table(path_2,sep=":",skip=33,nrows=53,as.is=TRUE)[,1],
              "char_freq_#",
              read.table(path_2,sep=":",skip=87,nrows=3,as.is=TRUE)[,1],
              "spam.01")
names(df) <- df.names # Adds headers to the df



spam_all <- df[df[, dim(df)[2]] == 1, ] # We have 1813 spam
no_spam_all <- df[df[, dim(df)[2]] == 0, ] # We have 2788 no-spam 
```

Separating the data

```{r}
set.seed(1234)

spamIndex <- which(spam.01 %in% c(1))
nospamIndex <- which(spam.01 %in% c(0))

spamTrain <- sample(spamIndex, size = ceiling(2/3*length(spamIndex)))
nospamTrain <- sample(nospamIndex, size = ceiling(2/3*length(nospamIndex)))
trainIndex <- union(nospamTrain, spamTrain)

trainData <- spam[trainIndex,]
testData <- spam[-trainIndex,]
```


```{r}
a = floor(dim(spam_all)[1]/3)*2;
b = floor(dim(no_spam_all)[1]/3)

set.seed(123)
aa = sample(a);
set.seed(123)
bb = sample(b)

spam_train = spam_all[aa, ]; spam_test = spam_all[setdiff(1:dim(spam_all)[1], aa), ]
no_spam_train = no_spam_all[bb, ]; no_spam_test = no_spam_all[setdiff(1:dim(no_spam_all)[1], bb), ]

```

```{r}

df_tr <- rbind.data.frame(no_spam_train, spam_train)

n<-dim(df_tr)[1]
p<-dim(df_tr)[2]-1 # Removes last column (response variable)
df_tr.01 <- df_tr[,p+1] # That is, the binary response variable
df_tr.vars <- as.matrix(df_tr[,1:p]) # That is X (n x p)
print("n_train = ");print(n);
print("p_train = ");print(p);
print("Proportion of spam e-mails = "); print(round(mean(df_tr.01),4))

df_test <- rbind.data.frame(no_spam_test, spam_test)

ntest<-dim(df_test)[1]
ptest<-dim(df_test)[2]-1 # Removes last column (response variable)
df_test.01 <- df_test[,p+1] # That is, the binary response variable
df_test.vars <- as.matrix(df_test[,1:p]) # That is X (n x p)
print("n_test = ");print(ntest);
print("p_test = ");print(ptest);
print("Proportion of spam e-mails = "); print(round(mean(df_test.01),4))




```

```{r, include=FALSE}
# simple solution using the caret package
library(caret)
set.seed(1234)

trainIndex <- createDataPartition(
  spam.01,
  times=1,
  p=2/3,
  list=FALSE
)
cat(paste("Proportion of training spam e-mails =",round(mean(spam.01[trainIndex]),2),sep=""))
cat(paste("Proportion of training spam e-mails =",round(mean(spam.01[-trainIndex]),2),sep=""))
```

Logistic regression fitted by maximum  likelihood (glm)


```{r}

# One variable by one

for (j in 1:dim(df_tr.vars)[2]) {
  aux0 <- as.numeric(df_tr.vars[, j])
  perm <- orderv(list(aux0))
  aux1 <- aux0[perm]
  aux2 <- df_tr.01[perm]
  glm.df_tr <- glm(aux2 ~ aux1,family=binomial())
  # summary(glm.df_tr)
  plot(aux1,aux2,xlab = df.names[j], ylab="Spam")
  lines(aux1, glm.df_tr$fitted.values,col=4)

}

```
```{r}
# General (ns com funciona la veritat...)

glm.df_tr <- glm(df_tr.01 ~ ., data = as.data.frame(df_tr.vars), family = binomial())

predictions_glm <- predict(glm.df_tr, newdata = as.data.frame(df_test.vars), type = "response")

roc_curve_glm <- roc(df_test.01, predictions_glm)
plot(roc_curve_glm, main = "ROC Curve", col = "blue")

predicted_classes_glm <- ifelse(predictions_glm >= 0.5, 1, 0)
misclassification_rate_glm <- mean(predicted_classes_glm != df_test.01)
print("missclassification rate for GLM ussing c = 1/2: "); print(misclassification_rate_glm)


```







Logistic regression fitted by Lasso (glmnet)

```{r}

set.seed(234) # To ensure replicability

fit_lasso <- glmnet(df_tr.vars, df_tr.01, family = "binomial")
cvfit_lasso = cv.glmnet(df_tr.vars, df_tr.01, family = "binomial", type.measure = "class")

plot(fit_lasso, xvar = "dev", label = TRUE)
plot(cvfit_lasso)

```
```{r}

final_fit_lasso <- glmnet(df_tr.vars, df_tr.01, family = "binomial", lambda = cvfit_lasso$lambda.min)

predictions_lasso <- predict(final_fit_lasso, newx = df_test.vars, type = "response")

roc_curve_lasso <- roc(df_test.01, predictions_lasso)
plot(roc_curve_lasso, main = "ROC Curve", col = "blue")

predicted_classes_lasso <- ifelse(predictions_lasso >= 0.5, 1, 0)
misclassification_rate_lasso <- mean(predicted_classes_lasso != df_test.01)
print("missclassification rate for LASSO ussing c = 1/2: "); print(misclassification_rate_lasso)



```

AFEGIT --> ES POT TREURE...



```{r}
cvfit_lasso$lambda.min
coefs_min_lasso <- coef(cvfit_lasso, s = "lambda.min")

print("The coefficients sorted by impact for lambda_{min} are: ")
coefs_min_lasso_aux = coefs_min_lasso[-1,]
coefs_min_lasso_aux[order(abs(coefs_min_lasso_aux))]

```
From these observations, we can observe which predictors are related to NO spam (negative ones)
and the ones related to spam (positive ones) and ordered.
The most relevant predictors to detect NO spam are: "george", "conference", "cs", "meeting"
The most relevant predictors to detect spam are: "$", "remove", "000", "money"
Some discarded predictors are: "857", "415", "capital_run_length_total" and "capital_run_length_longest"


```{r}
cvfit_lasso$lambda.1se
coefs_min_lasso <- coef(cvfit_lasso, s = "lambda.1se")

print("The coefficients sorted by impact for lambda_{min} are: ")
coefs_min_lasso_aux = coefs_min_lasso[-1,]
coefs_min_lasso_aux[order(abs(coefs_min_lasso_aux))]

```

From these observations, we can observe which predictors are related to NO spam (negative ones)
and the ones related to spam (positive ones) and ordered.
The most relevant predictors to detect NO spam are: "cs", "conference", "meeting", "hp"
The most relevant predictors to detect spam are: "$", "remove", "000", "money"
Some discarded predictors are: "make", "all", "mail" and "addresses"



k-nn binary regression (class)

```{r}


k_vec = c(1, 2, 5, 10, 20, 50, 100) # Rule of thumb (sqrt(n)) ~=50 so we pick 50...

for(j in 1:length(k_vec)){
  set.seed(555)
  knn_fit <- knn(train = df_tr.vars, test = df_tr.vars, cl = df_tr.01, k = k_vec[j])
  knn_cv <- knn.cv(train = df_tr.vars, cl = df_tr.01, k = k_vec[j])
  
  predictions_knn <- knn(train = df_tr.vars, test = df_test.vars, cl = df_tr.01, k = k_vec[j])
  predictions_knn <- as.integer(as.character(predictions_knn))

  roc_curve_knn <- roc(df_test.01, predictions_knn)
  plot(roc_curve_knn, main = "ROC Curve", col = "blue")
  
  predicted_classes_knn <- ifelse(predictions_knn >= 0.5, 1, 0)
  misclassification_rate_knn <- mean(predicted_classes_knn != df_test.01)
  print("missclassification rate for LASSO ussing c = 1/2 and k = to : ");print(k_vec[j]);
  print("is: "); print(misclassification_rate_knn )


}

k = 50
set.seed(555)
knn_fit <- knn(train = df_tr.vars, test = df_tr.vars, cl = df_tr.01, k = k)
knn_cv <- knn.cv(train = df_tr.vars, cl = df_tr.01, k = k_vec[j])

predictions_knn <- knn(train = df_tr.vars, test = df_test.vars, cl = df_tr.01, k = k)
predictions_knn <- as.integer(as.character(predictions_knn))

roc_curve_knn <- roc(df_test.01, predictions_knn)
plot(roc_curve_knn, main = "ROC Curve", col = "blue")

predicted_classes_knn <- ifelse(predictions_knn >= 0.5, 1, 0)
misclassification_rate_knn <- mean(predicted_classes_knn != df_test.01)
print("missclassification rate for LASSO ussing c = 1/2 and k = to : ");print(k);
  print("is: "); print(misclassification_rate_knn )

```



