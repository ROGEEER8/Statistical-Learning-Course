---
title: 'Assignment 5: GAM'
author: "Víctor Villegas, Roger Llorenç, Luis Sierra"
date: "2024-03-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Clears plots
while (dev.cur() != 1) {
  dev.off()
}
# Clears global environment
rm(list = ls())

set.seed(1234)
```

### Initial remark: double-blind trials

(Taken from [this](https://www.news-medical.net/health/What-is-a-Double-Blind-Trial.aspx) website)

In double-blind trials, the treatment patients have is unknown to both patients and doctors until after the study is concluded. This differs from other types of trials, such as simple blind trials where only the patients are unaware of the treatment they are receiving, whereas the doctors know.

Double-blind trials are a form of randomized trials and can be ‘upgraded’ to triple-blind trials, in which the statisticians or data clean-up personnel are also blind to treatments.

To be effective, it is generally recommended that double-blind trials include around 100-300 people. If treatments are highly effective, smaller numbers can be used but if only 30 or so patients are enrolled the study is unlikely to be beneficial.

The assignment of patients into treatments is typically done by computers, where the computer assigns each patient a code number and treatment group. The doctor and patients only know the code number to avoid bias, hence allowing the study to be double-blind.

## GAMs for hirsutism data

In this report we'll several GAM models (including semi-parametric models) explaining `FGm12` as a function of the variables that were measured at the beginning of the clinical trial and Treatment (treated as factor, which can by used as value of parameter by in function `s()`).

One of the advantages of GAM models is that they can overcome the curse of dimensionality.

Then we use functions `summary`, `plot`, `vis.gam` and `gam.check` to get an insight into the fitted models.

To do this, we will be using the following variables:

-   `Treatment`, with values 0 to 3.
-   `FGm0`, always greater than 15. Indicates the baseline hirsutism level at the randomization
-   `SysPres`, baseline systolic blood pressure.
-   `DiaPres`, baseline diastolic blood pressure.
-   `weight`
-   `height`

*Note: The term “baseline“ means that these variables were measured at the beginning of the clinical trial*

```{r}
library(mgcv)
# data separated by tab, fill in missing values
hirsutism <- read.table("hirsutism.dat",header=T, sep="\t",fill=TRUE)
# we're using the variable Treatment as a categorical predictor
hirsutism$Treatment <- as.factor(hirsutism$Treatment)

attach(hirsutism)
summary(hirsutism)
```

### 0. Linear additive model

```{r}
gam_0 <- gam(FGm12 ~ 
             (FGm0) + Treatment + (SysPres) + 
             (DiaPres) + (weight) + (height),
             data = hirsutism)
summary(gam_0)
```

-   **p-value:** [None]{.underline} of the following are statistically significant since their p-value is too high: `SysPres`, `weight`, `height`.

-   **R-squared (adjusted):** The model explains around 17% of the variance in `FGm12`.

-   **Deviance explained:** 24.4%.

    The previous two values lead us to conclude that the explanatory potential of this model is limited but not null.

-   **Number of observations:** notice that the `gam` functions removes the 8 observations with missing values. So `n=91`.

-   **Visualization:**

    ```{r}
    gam.check(gam_0)
    ```

### 1. Smoothing

-   Variable `Treatment` is a factor, so it doesn't have to be smoothed.

```{r}
gam_1 <- gam(FGm12 ~ 
             s(FGm0) + Treatment + s(SysPres) + 
             s(DiaPres) + s(weight) + s(height),
             data = hirsutism)
summary(gam_1)
```

-   **p-value:** the relevant values don't change.

-   **R-squared (adjusted):** The model explains around 28.8% of the variance in `FGm12`.

-   **Deviance explained:** 39.9%.

    The explanatory potential of the model has improved a considerable amount with respect to the previous one.

-   **Number of observations:** notice that the `gam` functions removes the 8 observations with missing values. So `n=91`.

-   **Visualization:**

    ```{r}
    gam.check(gam_1)
    vis.gam(gam_1,se=0,theta =40, phi = 10, d=4,nticks=3)

    vis.gam(gam_1,se=0,plot.type="contour",contour.col=1)
    points(Treatment,FGm0,col="blue")
    ```

    **Individual effects** of each explanatory variable:

    ```{r}
    plot(gam_1, residuals = TRUE, shade=TRUE, seWithMean=TRUE)
    ```

### 2. Joining variables

-   We fit jointly weight and height by `te(weight,height)` in order to capture the physical effect.
-   We fit jointly systolic and diastolic blood pressure by `te(SysPres,DiaPres)` in order to capture the physical effect.

```{r}
gam_2 <- gam(FGm12 ~ 
             s(FGm0) + Treatment
             + te(SysPres,DiaPres) + te(weight,height),
             data = hirsutism)
summary(gam_2)
```

-   **p-value:** There hasn't been an improvement.

-   **R-squared (adjusted):** 31.6%

-   **Deviance explained:** It has increased to 44.5%.

    The increase of these two last values means an improvement in the explanatory potential of the model, that is, this model is better than the previous one.

-   **Visualization:**

    ```{r}
    gam.check(gam_2)

    vis.gam(gam_2,se=0,theta =40, phi = 10, d=4,nticks=3)

    vis.gam(gam_2,se=0,plot.type="contour",contour.col=1)
    points(Treatment,FGm0,col="blue")
    ```

    **Individual effects** of each explanatory variable:

    ```{r}
    plot(gam_2, residuals = TRUE, shade=TRUE, seWithMean=TRUE)
    ```

    **Joint effects** of a pair of variables

    ```{r}
    vis.gam(gam_2, view=c("weight","height"), plot.type = "persp", theta=40, phi=10,d=4,nticks=3)
    vis.gam(gam_2, view=c("weight","height"), plot.type = "contour",contour.col=1)
    points(weight,height,col="blue")

    vis.gam(gam_2, view=c("SysPres","DiaPres"), plot.type = "persp", theta=40, phi=10,d=4,nticks=3)
    vis.gam(gam_2, view=c("SysPres","DiaPres"), plot.type = "contour",contour.col=1)
    points(SysPres,DiaPres,col="blue")
    ```

**Refinements** that can be done are:

-   Certain variables could be removed from the model because the corresponding `p-values` are large.

### 3. Refining of (2)

Now we remove non-significant variables from the model one at a time, in decreasing order of p-values, until all variables are significant.

```{r}
gam_3 <- gam(FGm12 ~ 
             s(FGm0) + Treatment
             + te(SysPres,DiaPres),
             data = hirsutism)
summary(gam_3)
```

```{r}
gam_3 <- gam(FGm12 ~ 
             s(FGm0) + Treatment,
             data = hirsutism)
summary(gam_3)
```

-   **p-value:** the only variable left is `FGm0`.

-   **R-squared (adjusted):** 27,7%

-   **Deviance explained:** 34,1%.

    The increase of these two last values means an improvement in the explanatory potential of the model, that is, this model is better than the previous one.

-   **Visualization:**

    ```{r}
    gam.check(gam_3)

    vis.gam(gam_3,se=0,theta =40, phi = 10, d=4,nticks=3)

    vis.gam(gam_1,se=0,plot.type="contour",contour.col=1)
    points(Treatment,FGm0,col="blue")
    ```

    ```{r}
    plot(gam_3, residuals = TRUE, seWithMean=TRUE)
    ```

## 4. Treatment as a parameter of `s()`

```{r}
gam_1b <- gam(FGm12 ~ 
             s(FGm0, by=Treatment) + s(SysPres, by=Treatment) + 
             s(DiaPres, by=Treatment) + s(weight, by=Treatment) + s(height, by=Treatment),
             data = hirsutism)
summary(gam_1b)
```

## 5. A semi-parametric model

Sometimes some of the explanatory variables involved in the definition of an additive model (or a generalized additive model) affect the response variable linearly. If this is known in advance, the GAM model can be reformulated allowing some of the functions to be linear.

# Checking

Now we test the null hypothesis that states the final model is correct again the alternative that states that the full model is better.

```{r}
anova(gam9,full.gam.k,test="F")
```
